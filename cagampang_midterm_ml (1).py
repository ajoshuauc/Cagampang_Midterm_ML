# -*- coding: utf-8 -*-
"""Cagampang_Midterm_ML.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XEqToQP8e8NHcQPvz-S3R-oof4ZgTC72
"""

import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
from transformers import BertTokenizer, BertModel
from sklearn.preprocessing import LabelEncoder
from torch.optim import Adam
import spacy

# Load spaCy model
nlp = spacy.load("en_core_web_sm")

# Sample conversational dataset
data = [
    {
        "user_input": "What's the weather like today?",
        "intent": "GetWeather",
        "entities": {
            "location": None,
            "date": "today"
        }
    },
    {
        "user_input": "Book a flight to London",
        "intent": "BookFlight",
        "entities": {
            "destination": "London",
            "date": None
        }
    },
    {
        "user_input": "Play some music",
        "intent": "PlayMusic",
        "entities": {}
    },
    {
        "user_input": "What's the time in New York?",
        "intent": "GetTime",
        "entities": {
            "location": "New York",
            "date": None
        }
    },
    {
        "user_input": "Reserve a table for two at a restaurant",
        "intent": "BookRestaurant",
        "entities": {
            "party_size": 2,
            "restaurant": None
        }
    }
]

# Create a DataFrame
df = pd.DataFrame(data)

# Encode intents
label_encoder = LabelEncoder()
df['intent_encoded'] = label_encoder.fit_transform(df['intent'])

# Tokenization
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
inputs = tokenizer(df['user_input'].tolist(), padding=True, truncation=True, return_tensors="pt")

# Create dataset and DataLoader
labels = torch.tensor(df['intent_encoded'].values, dtype=torch.long)
dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)
train_loader = DataLoader(dataset, batch_size=2, shuffle=True)

# Define the model
class BertIntentClassifier(nn.Module):
    def __init__(self, num_classes):
        super(BertIntentClassifier, self).__init__()
        self.bert = BertModel.from_pretrained('bert-base-uncased')
        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)

    def forward(self, input_ids, attention_mask, token_type_ids=None):
        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)
        logits = self.classifier(outputs.pooler_output)
        return logits

# Create model instance
num_classes = len(label_encoder.classes_)
model = BertIntentClassifier(num_classes)

# Move model to GPU if available
if torch.cuda.is_available():
    model = model.to('cuda')

# Define optimizer
optimizer = Adam(model.parameters(), lr=1e-5)

# Training loop
for epoch in range(5):  # Number of epochs
    model.train()
    for batch in train_loader:
        input_ids, attention_mask, label = batch
        if torch.cuda.is_available():
            input_ids = input_ids.to('cuda')
            attention_mask = attention_mask.to('cuda')
            label = label.to('cuda')

        optimizer.zero_grad()
        outputs = model(input_ids, attention_mask)
        loss = nn.CrossEntropyLoss()(outputs, label)
        loss.backward()
        optimizer.step()

    print(f"Epoch {epoch + 1}, Loss: {loss.item()}")

# Prediction function
def predict_intent(user_input):
    inputs = tokenizer(user_input, return_tensors="pt", padding=True, truncation=True)

    if torch.cuda.is_available():
        inputs = {k: v.to('cuda') for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)  # Pass the entire inputs dictionary
        predicted_class = torch.argmax(outputs, dim=1).item()

    return label_encoder.inverse_transform([predicted_class])[0]

# Entity recognition function using spaCy
def extract_entities(user_input):
    doc = nlp(user_input)
    entities = {ent.label_: [] for ent in doc.ents}

    for ent in doc.ents:
        entities[ent.label_].append(ent.text)

    return {key: value for key, value in entities.items() if value}  # Return only non-empty entities

# Feedback storage
feedback_data = []

# Example usage
print("You can start typing your requests. Type 'exit' or 'quit' to stop.")
while True:
    user_input = input("You: ")
    if user_input.lower() in ["exit", "quit"]:
        print("Exiting the chat. Goodbye!")
        break

    intent = predict_intent(user_input)
    entities = extract_entities(user_input)

    # Custom handling of specific entities based on the new dataset
    if intent == "GetWeather":
        if "date" not in entities or not entities["date"]:
            entities["date"] = "today"  # Default to 'today' if not provided
    elif intent == "BookFlight":
        destination = [ent for ent in entities.get("GPE", [])]  # GPE = Geopolitical Entity
        if destination:
            entities["destination"] = destination[0]  # Use the first found destination
        else:
            entities["destination"] = None  # Default if no destination found

    print(f"Predicted Intent: {intent}")
    print(f"Extracted Entities: {entities}")

    # Collect user feedback
    rating = input("Rate the response (1-5, where 5 is excellent): ")
    feedback_data.append({
        "user_input": user_input,
        "predicted_intent": intent,
        "extracted_entities": entities,
        "rating": rating
    })

    print("Thank you for your feedback!")

# Display feedback collected (for demonstration purposes)
print("\nFeedback Collected:")
for feedback in feedback_data:
    print(feedback)

